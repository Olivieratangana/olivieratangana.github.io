---
title: "secml: Secure and explainable machine learning in Python"
collection: publications
permalink: /publications/2022-01-01-secml-Secure-and-explainable-machine-learning-in-Python
pubtype: journal
date: 2022-01-01
venue: 'SoftwareX'
paperurl: 'https://www.sciencedirect.com/science/article/pii/S2352711022000656'
citation: ' Maura Pintor,  Luca Demetrio,  Angelo Sotgiu,  Marco Melis,  Ambra Demontis,  Battista Biggio, &quot;secml: Secure and explainable machine learning in Python.&quot; SoftwareX, 2022.'
---
Abstract:

We present secml, an open-source Python library for secure and explainable machine learning. It implements the most popular attacks against machine learning, including test-time evasion attacks to generate adversarial examples against deep neural networks and training-time poisoning attacks against support vector machines and many other algorithms. These attacks enable evaluating the security of learning algorithms and the corresponding defenses under both white-box and black-box threat models. To this end, secml provides built-in functions to compute security evaluation curves, showing how quickly classification performance decreases against increasing adversarial perturbations of the input data. secml also includes explainability methods to help understand why adversarial attacks succeed against a given model, by visualizing the most influential features and training prototypes contributing to each decision. It is distributed under the Apache License 2.0 and hosted at https://github.com/pralab/secml.

[Access paper here](https://www.sciencedirect.com/science/article/pii/S2352711022000656){:target="_blank"}

BibTeX: 
>@article{PINTOR2022101095,<br>    author = {Pintor, Maura and Demetrio, Luca and Sotgiu, Angelo and Melis, Marco and Demontis, Ambra and Biggio, Battista},<br>    title = {secml: Secure and explainable machine learning in Python},<br>    journal = {SoftwareX},<br>    volume = {18},<br>    pages = {101095},<br>    year = {2022},<br>    issn = {2352-7110},<br>    doi = {https://doi.org/10.1016/j.softx.2022.101095},<br>    url = {https://www.sciencedirect.com/science/article/pii/S2352711022000656},<br>    keywords = {Machine learning, Security, Adversarial attacks, Explainability, Python3}<br>}<br>