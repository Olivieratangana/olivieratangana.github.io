---
title: "ALOHA: An Architectural-Aware Framework for Deep Learning at the Edge"
collection: publications
permalink: /publications/2018-01-01-ALOHA-An-Architectural-Aware-Framework-for-Deep-Learning-at-the-Edge
pubtype: proceeding
authors:  P. Meloni,  D. Loi,  G. Deriu,  A. Pimentel,  D. Sapra,  B. Moser,  N. Shepeleva,  F. Conti,  L. Benini,  O. Ripolles,  D. Solans,  Maura Pintor,  B. Biggio,  T. Stefanov,  S. Minakova,  N. Fragoulis,  I. Theodorakopoulos,  M. Masin,  F. Palumbo
date: 2018-01-01
venue: 'In the proceedings of Proceedings of the Workshop on INTelligent Embedded Systems Architectures and Applications'
paperurl: 'https://doi.org/10.1145/3285017.3285019'
citation: ' P. Meloni,  D. Loi,  G. Deriu,  A. Pimentel,  D. Sapra,  B. Moser,  N. Shepeleva,  F. Conti,  L. Benini,  O. Ripolles,  D. Solans,  Maura Pintor,  B. Biggio,  T. Stefanov,  S. Minakova,  N. Fragoulis,  I. Theodorakopoulos,  M. Masin,  F. Palumbo, &quot;ALOHA: An Architectural-Aware Framework for Deep Learning at the Edge.&quot; In the proceedings of Proceedings of the Workshop on INTelligent Embedded Systems Architectures and Applications, 2018.'
---
Abstract:

Novel Deep Learning (DL) algorithms show ever-increasing accuracy and precision in multiple application domains. However, some steps further are needed towards the ubiquitous adoption of this kind of instrument. First, effort and skills required to develop newDL models, or to adapt existing ones to new use-cases, are hardly available for small- and medium-sized businesses. Second, DL inference must be brought at the edge, to overcome limitations posed by the classically-used cloud computing paradigm. This requires implementation on low-energy computing nodes, often heterogenous and parallel, that are usually more complex to program and to manage. This work describes the ALOHA framework, that proposes a solution to these issue by means of an integrated toolflow that automates most phases of the development process. The framework introduces architecture-awareness, considering the target inference platform very early, already during algorithm selection, and driving the optimal porting of the resulting embedded application. Moreover it considers security, power efficiency and adaptiveness as main objectives during the whole development process.

[Access paper here](https://doi.org/10.1145/3285017.3285019){:target="_blank"}

BibTeX: 
>@conference{10.1145/3285017.3285019,<br>    author = {Meloni, P. and Loi, D. and Deriu, G. and Pimentel, A. D. and Sapra, D. and Moser, B. and Shepeleva, N. and Conti, F. and Benini, L. and Ripolles, O. and Solans, D. and Pintor, Maura and Biggio, B. and Stefanov, T. and Minakova, S. and Fragoulis, N. and Theodorakopoulos, I. and Masin, M. and Palumbo, F.},<br>    title = {ALOHA: An Architectural-Aware Framework for Deep Learning at the Edge},<br>    year = {2018},<br>    isbn = {9781450365987},<br>    publisher = {Association for Computing Machinery},<br>    address = {New York, NY, USA},<br>    url = {https://doi.org/10.1145/3285017.3285019},<br>    doi = {10.1145/3285017.3285019},<br>    booktitle = {Proceedings of the Workshop on INTelligent Embedded Systems Architectures and Applications},<br>    pages = {19â€“26},<br>    numpages = {8},<br>    keywords = {deep learning, computer aided design, convolutional neural networks},<br>    location = {Turin, Italy},<br>    series = {INTESA '18}<br>}<br>