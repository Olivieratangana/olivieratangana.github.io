@article{zheng2021adversarial,
  title={Why Adversarial Reprogramming Works, When It Fails, and How to Tell the Difference},
  abstract={Adversarial reprogramming allows repurposing a machine-learning model to perform a different task. For example, a model trained to recognize animals can be reprogrammed to recognize digits by embedding an adversarial program in the digit images provided as input. Recent work has shown that adversarial reprogramming may not only be used to abuse machine-learning models provided as a service, but also beneficially, to improve transfer learning when training data is scarce. However, the factors affecting its success are still largely unexplained. In this work, we develop a first-order linear model of adversarial reprogramming to show that its success inherently depends on the size of the average input gradient, which grows when input gradients are more aligned, and when inputs have higher dimensionality. The results of our experimental analysis, involving fourteen distinct reprogramming tasks, show that the above factors are correlated with the success and the failure of adversarial reprogramming.},
  author={Zheng, Yang and Feng, Xiaoyi and Xia, Zhaoqiang and Jiang, Xiaoyue and Demontis, Ambra and Pintor, Maura and Biggio, Battista and Roli, Fabio},
  journal={arXiv preprint arXiv:2108.11673},
  url = {https://arxiv.org/abs/2108.11673},
  year={2021},
  annote={others}
}

@article{demontis2022survey,
  title={A Survey on Reinforcement Learning Security with Application to Autonomous Driving},
  author={Demontis, Ambra and Pintor, Maura and Demetrio, Luca and Grosse, Kathrin and Lin, Hsiao-Ying and Fang, Chengfang and Biggio, Battista and Roli, Fabio},
  journal={arXiv preprint arXiv:2212.06123},
  year={2022},
  abstract={Reinforcement learning allows machines to learn from their own experience. Nowadays, it is used in safety-critical applications, such as autonomous driving, despite being vulnerable to attacks carefully crafted to either prevent that the reinforcement learning algorithm learns an effective and reliable policy, or to induce the trained agent to make a wrong decision. The literature about the security of reinforcement learning is rapidly growing, and some surveys have been proposed to shed light on this field. However, their categorizations are insufficient for choosing an appropriate defense given the kind of system at hand. In our survey, we do not only overcome this limitation by considering a different perspective, but we also discuss the applicability of state-of-the-art attacks and defenses when reinforcement learning algorithms are used in the context of autonomous driving.},
  annote={others}
}

