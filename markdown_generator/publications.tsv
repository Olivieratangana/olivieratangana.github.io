pub_date	title	venue	excerpt	citation	url_slug	paper_url
2020-10-01	Detecting Anomalies from Video-Sequences: A Novel Descriptor	25th International Conference on Pattern Recognition	We present a novel descriptor for crowd behavior analysis and anomaly detection. The goal is to measure by appropriate patterns the speed of formation and disintegration of groups in the crowd. This descriptor is inspired by the concept of one-dimensional local binary patterns: in our case, such patterns depend on the number of group observed in a time window. An appropriate measurement unit, named trit (trinary digit), represents three possible dynamic states of groups on a certain frame. Our hypothesis is that abrupt variations of the groups' number may be due to an anomalous event that can be accordingly detected, by translating these variations on temporal trit-based sequence of strings which are significantly different from the one describing the no-anomaly one. Due to the peculiarity of the rationale behind this work, relying on the number of groups, three different methods of people group’s extraction are compared. Experiments are carried out on the Motion-Emotion benchmark data set. Reported results point out in which cases the trit-based measurement of group dynamics allows us to detect the anomaly. Besides the promising performance of our approach, we show how it is correlated with the anomaly typology and the camera's perspective to the crowd's flow (frontal, lateral).	Giulia Orrù, Davide Ghiani, Maura Pintor, Gian Luca Marcialis, Fabio Roli. 'Detecting Anomalies from Video-Sequences: A Novel Descriptor', 25th International Conference on Pattern Recognition 2020	orru2020-detecting-anomalies-from-video-sequences	https://arxiv.org/pdf/2010.06407.pdf
2019-08-14	Why do adversarial attacks transfer? explaining transferability of evasion and poisoning attacks	28th USENIX Security Symposium 2019	Transferability captures the ability of an attack against a machine-learning model to be effective against a different, potentially unknown, model. Empirical evidence for transferability has been shown in previous work, but the underlying reasons why an attack transfers or not are not yet well understood. In this paper, we present a comprehensive analysis aimed to investigate the transferability of both test-time evasion and training-time poisoning attacks. We provide a unifying optimization framework for evasion and poisoning attacks, and a formal definition of transferability of such attacks. We highlight two main factors contributing to attack transferability: the intrinsic adversarial vulnerability of the target model, and the complexity of the surrogate model used to optimize the attack. Based on these insights, we define three metrics that impact an attack’s transferability. Interestingly, our results derived from theoretical analysis hold for both evasion and poisoning attacks, and are confirmed experimentally using a wide range of linear and non-linear classifiers and datasets.	Ambra Demontis, Marco Melis, Maura Pintor, Matthew Jagielski, Battista Biggio, Alina Oprea, Cristina Nita-Rotaru, Fabio Roli. 'Why do adversarial attacks transfer? explaining transferability of evasion and poisoning attacks.', 28th USENIX Security Symposium 2019	demontis19-why-do-adversarial-attacks-transfer	https://www.usenix.org/system/files/sec19-demontis.pdf
2018-10-04	ALOHA: an architectural-aware framework for deep learning at the edge	Proceedings of the Workshop on INTelligent Embedded Systems Architectures and Applications	Novel Deep Learning (DL) algorithms show ever-increasing accuracy and precision in multiple application domains. However, some steps further are needed towards the ubiquitous adoption of this kind of instrument. First, effort and skills required to develop newDL models, or to adapt existing ones to new use-cases, are hardly available for small- and medium-sized businesses. Second, DL inference must be brought at the edge, to overcome limitations posed by the classically-used cloud computing paradigm. This requires implementation on low-energy computing nodes, often heterogenous and parallel, that are usually more complex to program and to manage. This work describes the ALOHA framework, that proposes a solution to these issue by means of an integrated toolflow that automates most phases of the development process. The framework introduces architecture-awareness, considering the target inference platform very early, already during algorithm selection, and driving the optimal porting of the resulting embedded application. Moreover it considers security, power efficiency and adaptiveness as main objectives during the whole development process.	Paolo Meloni, Daniela Loi, Gianfranco Deriu, Andy D Pimentel, Dolly Sapra, Bernhard Moser, Natalia Shepeleva, Francesco Conti, Luca Benini, Oscar Ripolles, David Solans, Maura Pintor, Battista Biggio, Todor Stefanov, Svetlana Minakova, Nikolaos Fragoulis, Ilias Theodorakopoulos, Michael Masin, Francesca Palumbo. 'ALOHA: an architectural-aware framework for deep learning at the edge', Proceedings of the Workshop on INTelligent Embedded Systems Architectures and Applications 2018	meloni18-aloha-an-architectural-aware-framework	http://liacs.leidenuniv.nl/~stefanovtp/pdf/INTESA_18.pdf
2019-04-30	Optimization and deployment of CNNs at the edge: the ALOHA experience	Proceedings of the 16th ACM International Conference on Computing Frontiers	Deep learning (DL) algorithms have already proved their effectiveness on a wide variety of application domains, including speech recognition, natural language processing, and image classification. To foster their pervasive adoption in applications where low latency, privacy issues and data bandwidth are paramount, the current trend is to perform inference tasks at the edge. This requires deployment of DL algorithms on low-energy and resource-constrained computing nodes, often heterogenous and parallel, that are usually more complex to program and to manage without adequate support and experience. In this paper, we present ALOHA, an integrated tool flow that tries to facilitate the design of DL applications and their porting on embedded heterogenous architectures. The proposed tool flow aims at automating different design steps and reducing development costs. ALOHA considers hardware-related variables and security, power efficiency, and adaptivity aspects during the whole development process, from pre-training hyperparameter optimization and algorithm configuration to deployment.	Paolo Meloni, Daniela Loi, Paola Busia, Gianfranco Deriu, Andy D Pimentel, Dolly Sapra, Todor Stefanov, Svetlana Minakova, Francesco Conti, Luca Benini, Maura Pintor, Battista Biggio, Bernhard Moser, Natalia Shepeleva, Nikos Fragoulis, Ilias Theodorakopoulos, Michael Masin, Francesca Palumbo. 'Optimization and deployment of CNNs at the edge: the ALOHA experience', Proceedings of the 16th ACM International Conference on Computing Frontiers 2019	meloni19-optimization-and-deployment	http://liacs.leidenuniv.nl/~stefanovtp/pdf/CF_19.pdf
2018-07-30	Be Right Beach: A Social IoT system for sustainable tourism based on beach overcrowding avoidance	2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)	The coastal erosion is becoming of paramount importance for many countries. Many studies demonstrated that in some cases beach overcrowding is the primary cause of coastal erosion. The goal of this work is to design, implement and test a system (BRB-Be Right Beach) that foster beach overcrowding avoidance and allows anyone to choose the right beach to go for having the best experience. The major requirement of our system is to have maximum accuracy (no errors, that is real-time data only are used) in the information provided to the users. The system exploits the Social Internet of Things paradigm to implement a classifier trained by a community of smartphones brought by the owners to the beaches. The BRB sensor network consists of control units equipped with a UV sensor, a thermometer, a humidity sensor and a camera for crowdedness estimation. Data are collected by a cloud platform that provides any user with information about beaches and suggestions where to go, based on users preferences like weather, crowdedness, time of travel, and so on.	Roberto Girau, Enrico Ferrara, Maura Pintor, Mariella Sole, Daniele Giusto. 'Be Right Beach: A Social IoT system for sustainable tourism based on beach overcrowding avoidance', 2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData) 2018	girau18-be-right-beach	https://www.researchgate.net/profile/Roberto_Girau/publication/332179808_Be_Right_Beach_A_Social_IoT_System_for_Sustainable_Tourism_Based_on_Beach_Overcrowding_Avoidance/links/5ca4bb2ca6fdcc12ee8fcc07/Be-Right-Beach-A-Social-IoT-System-for-Sustainable-Tourism-Based-on-Beach-Overcrowding-Avoidance.pdf
2021-06-18	Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples	arXiv preprint arXiv:2106.09947  (2021)	Evaluating robustness of machine-learning models to adversarial examples is a challenging problem. Many defenses have been shown to provide a false sense of security by causing gradient-based attacks to fail, and they have been broken under more rigorous evaluations. Although guidelines and best practices have been suggested to improve current adversarial robustness evaluations, the lack of automatic testing and debugging tools makes it difficult to apply these recommendations in a systematic manner. In this work, we overcome these limitations by (i) defining a set of quantitative indicators which unveil common failures in the optimization of gradient-based attacks, and (ii) proposing specific mitigation strategies within a systematic evaluation protocol. Our extensive experimental analysis shows that the proposed indicators of failure can be used to visualize, debug and improve current adversarial robustness evaluations, providing a first concrete step towards automatizing and systematizing current adversarial robustness evaluations. Our open-source code is available at: https://github.com/pralab/IndicatorsOfAttackFailure. 	Maura Pintor, Luca Demetrio, Angelo Sotgiu, Giovanni Manca, Ambra Demontis, Nicholas Carlini, Battista Biggio, Fabio Roli, 'Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples', arXiv preprint arXiv:2106.09947, 2021	pintor-indicators	https://arxiv.org/pdf/2106.09947.pdf
2021-08-26	Why Adversarial Reprogramming Works, When It Fails, and How to Tell the Difference	arXiv preprint arXiv:2108.11673  (2021)	Adversarial reprogramming allows repurposing a machine-learning model to perform a different task. For example, a model trained to recognize animals can be reprogrammed to recognize digits by embedding an adversarial program in the digit images provided as input. Recent work has shown that adversarial reprogramming may not only be used to abuse machine-learning models provided as a service, but also beneficially, to improve transfer learning when training data is scarce. However, the factors affecting its success are still largely unexplained. In this work, we develop a first-order linear model of adversarial reprogramming to show that its success inherently depends on the size of the average input gradient, which grows when input gradients are more aligned, and when inputs have higher dimensionality. The results of our experimental analysis, involving fourteen distinct reprogramming tasks, show that the above factors are correlated with the success and the failure of adversarial reprogramming. 	Yang Zheng, Xiaoyi Feng, Zhaoqiang Xia, Xiaoyue Jiang, Ambra Demontis, Maura Pintor, Battista Biggio, Fabio Roli, 'Why Adversarial Reprogramming Works, When It Fails, and How to Tell the Difference', arXiv preprint arXiv:2108.11673, 2021	zheng-reprogramming	https://arxiv.org/abs/2108.11673
2021-09-28	Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints	Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)	Evaluating adversarial robustness amounts to finding the minimum perturbation needed to have an input sample misclassified. The inherent complexity of the underlying optimization requires current gradient-based attacks to be carefully tuned, initialized, and possibly executed for many computationally-demanding iterations, even if specialized to a given perturbation model. In this work, we overcome these limitations by proposing a fast minimum-norm (FMN) attack that works with different ℓp-norm perturbation models (p=0,1,2,∞), is robust to hyperparameter choices, does not require adversarial starting points, and converges within few lightweight steps. It works by iteratively finding the sample misclassified with maximum confidence within an ℓp-norm constraint of size ϵ, while adapting ϵ to minimize the distance of the current sample to the decision boundary. Extensive experiments show that FMN significantly outperforms existing attacks in terms of convergence speed and computation time, while reporting comparable or even smaller perturbation sizes.	Maura Pintor, Fabio Roli, Wieland Brendel, Battista Biggio, 'Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints', Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021), 2021	pintor-fast-minimum-norm	https://arxiv.org/pdf/2102.12827.pdf
2021-10-6	 Slope: A First-order Approach for Measuring Gradient Obfuscation	29th European Symposium on Artificial Neural Networks, Computational  Intelligence and Machine Learning	Evaluating adversarial robustness is a challenging problem. Many defenses have been shown to provide a false sense of security by unintentionally obfuscating gradients, hindering the optimization process of gradient-based attacks. Such defenses have been subsequently shown to fail against adaptive attacks crafted to circumvent gradient obfuscation. In this work, we present Slope, a metric that detects obfuscated gradients by comparing the expected and the actual increase of the attack loss after one iteration. We show that our metric can detect the presence of obfuscated gradients in many documented cases, providing a useful debugging tool towards improving adversarial robustness evaluations.	Maura Pintor, Luca Demetrio, Giovanni Manca, Battista Biggio, Fabio Roli, 'Slope: A First-order Approach for Measuring Gradient Obfuscation', 29th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2021), 2021	pintor-slope	https://www.esann.org/sites/default/files/proceedings/2021/ES2021-99.pdf